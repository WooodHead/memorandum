---
title: Chapter3-05. statistical hypothesis
book_title: Mathematical statistics
book_chapter: 3
book_section: 5
---

## 3.5 Statistical hypothesis


## 3.5.3. Formulation of hypothesis testing

### Definition testing function
* $(\mathcal{X}, \mathcal{A})$,
    * measurable space
* $\Theta \subseteq \mathbb{R}^{p}$,
    * parameters
* $$\{P\}_{\theta \in \Theta}$$,
    * probability measure over $(\mathcal{X},\mathcal{A})$,

Subset $\Theta_{H} \subseteq \Theta$ is said to be hypothesis.
If $\Theta_{H}$

<div class="end-of-statement" style="text-align: right">■</div>

### Example 3.25
* $n \in \mathbb{N}$,
* $\Theta := [0, 1]$,
* $\mathcal{X} := \{0, 1, \ldots, n\}$,
* $\mu: \mathcal{X} \rightarrow [0, 1]$
    * countable measure
* $P_{\theta}:= B(n, \theta)$
    * binominal distribution
* $\theta_{i} \in \Theta$,
    * $0 < \theta_{0} < \theta_{1} < 1$,

$$
\begin{eqnarray}
    p_{\theta}(x)
    & := &
        \frac{d P_{\theta}}{d \mu}(x)
    \nonumber
    \\
    & = &
        \left(
            \begin{array}{c}
                n \\
                x
            \end{array}
        \right)
        \theta^{x}
        (1 - \theta)^{n - x}
    \nonumber
\end{eqnarray}
$$

We consinder hypothesis test:

$$
    \Theta_{H}
    :=
    \{\theta_{0}\},
    \
    \Theta_{K}
    :=
    \{\theta_{0}\}
    .
$$

We have

$$
    \log
        \frac{
            p_{\theta_{0}}(x)
        }{
            p_{\theta_{1}}(x)
        }
    =
    ax
    +
    n \log
        \frac{
            1 - \theta_{1}
        }{
            1 - \theta_{0}
        }
$$

where

$$
    a
    :=
    \log
        \frac{
            \theta_{1}/(1 - \theta_{1})
        }{
            \theta_{0}/(1 - \theta_{0})
        }
    >
    0
    .
$$

<div class="end-of-statement" style="text-align: right">■</div>

### 3.5.5 Monotone likehood ratio and composite hypothesis test
* $\Theta \subseteq \mathbb{R}$,
* $(\mathcal{X}, \mathcal{A})$,
    * measurable space
* $$\mathcal{P} := \{P_{\theta} \}_{\theta \in \Theta}$$,
    * family of probability distribution over $(\mathcal{X}, \mathcal{A})$
* $\mu: \mathcal{X} \rightarrow [0, \infty)$
    * $\sigma$ finite measure on $(\mathcal{X}, \mathcal{A})$

Assumptions

$$
    \forall \theta,
    \
    \mu
    \gg
    P_{\theta}
    .
$$

### Definition monotone likelihodd ratio
* $T: \mathcal{X} \rightarrow \mathbb{R}_{\ge 0}$
    * measurable function

$$
    \mathcal{X}_{\theta_{1}, \theta_{2}}
    :=
    \mathcal{X}
    \setminus
    \{x \mid p_{\theta_{1}}(x) = p_{\theta_{2}}(x) = 0\}
    \quad
    (\theta_{1}, \theta_{2} \in \Theta)
$$

$\mathcal{P}$ is said to be monotone likelihood ration with respect to $T$ if

$$
\begin{eqnarray}
    \forall \theta_{1}, \theta_{2} \in \Theta,
    \
    \theta_{1} < \theta_{2},
    \
    \exists H_{\theta_{1}, \theta_{2}}:T(\mathcal{X}) \rightarrow [0, \infty]
    \text{ s.t. }
    & &
        H \text{ is non-decreasing},
    \nonumber
    \\
    & &
        \forall x \in
        \mathcal{X}_{\theta_{1}, \theta_{2}}
        ,
        \
        \frac{p_{\theta_{2}}}{p_{\theta_{1}}}(x)
        =
        H_{\theta_{1}, \theta_{2}}(T(x))
    \nonumber
\end{eqnarray}
$$

We assume $c/0 = \infty$ for $c > 0$.

<div class="end-of-statement" style="text-align: right">■</div>

### Example 3.26
* $\Theta \subseteq \mathbb{R}$,
* $$\mathcal{P} := \{P_{\theta} \}_{\theta \in \Theta}$$,
    * one prameter exponential family

That is, there exist $g: \mathcal{X} \rightarrow \mathbb{R}_{\ge 0}$, $a: \Theta \rightarrow \mathbb{R}$, $\psi: \Theta \rightarrow \mathbb{R}$ such that

$$
    p_{\theta}(x)
    :=
    g(x)
    \exp
    \left(
        a(\theta) T(x)
        -
        \psi(\theta)
    \right)
    \
    (x \in \mathcal{X})
    .
$$

If $a$ is non-decreasing function, then $\mathcal{P}$ is monotone likelihood ration with respect to $T$.

<div class="end-of-statement" style="text-align: right">■</div>

### Theorem 3.27
* $$\mathcal{P} := \{P_{\theta}\}_{\theta \in \Theta}$$,
    * monotone likelihood ratio with respect to $T$
* $$\{\theta \mid \theta > \theta_{0}\} \neq \emptyset$$,
* $c \in \mathbb{R}$,
* $\gamma \in [0, 1]$,

(a) Let

$$
\begin{eqnarray}
    \phi_{0}(x)
    & := &
        \begin{cases}
            1
            &
                (T(x) > c)
            \\
            \gamma
            &
                (T(x) = c)
            \\
            0
            &
                (T(x) < c)
        \end{cases}
    \nonumber
    \\
    & = &
        1_{\{x \mid T(x) >c\}}(x)
        +
        \gamma
        1_{\{x \mid T(x) =c\}}(x)
        \label{chap03_03_22_test}
\end{eqnarray}
$$

If $$\mathrm{E}_{\theta_{0}} \left[ \phi_{0} \right] > 0$$, then $\phi_{0}$ is the most powerful test at level $$\mathrm{E}_{\theta_{0}}[\phi_{0}]$$ for hypothesis test

$$
\begin{equation}
    \Theta_{H}
    :=
    \{\theta \mid \theta \le \theta_{0}\},
    \
    \Theta_{K}
    :=
    \{\theta \mid \theta > \theta_{0}\},
    \label{chap03_03_23_hypothesis_test}
\end{equation}
$$

(b) For $\alpha \in (0, 1)$,

$$
    \exists c \in \mathbb{R},
    \
    \gamma \in [0, 1],
    \
    \text{ s.t. }
    \
    \phi_{0}: \eqref{chap03_03_23_hypothesis_test}
    \text{the most powerful test at level } \alpha
$$

### proof
Let

$$
    k
    :=
    \inf
    \left\{
        \frac{p_{\theta_{1}}(x)}{p_{\theta_{0}}(x)}
        \mid
        x \in \mathcal{X}_{\theta_{1}, \theta_{2}},
        \
        T(x) \ge c
    \right\}
    .
$$

Then $k \in \mathbb{R}_{\ge 0}$.
Indeed, 

$$
    \mu(
        \{
            x \in \mathcal{X}_{\theta_{0}, \theta_{1}}
            \mid
            p_{\theta_{0}}(x)
            \neq
            0,
            \
            T(x) \ge 0
        \}
    )
    > 0
$$

since

$$
    \int_{\mathcal{X}_{\theta_{0}, \theta_{1}}}
        1_{\{T \ge c\}}(x)
        p_{\theta_{0}}(x)
    \ \mu(dx)
    =
    P_{\theta_{0}}(T \ge c)
    \ge
    \mathrm{E}_{\theta_{0}}[\phi_{0}]
    >
    0
    .
$$

Morever $$p_{\theta_{1}} < \infty \ \mu \text{-a.e.}$$ by definition.
Therefore $k < \infty$.

Now we show that 

$$
\begin{eqnarray}
    p_{\theta_{1}}(x)
    >
    kp_{\theta_{0}}(x),
    \
    x \in \mathcal{X}_{\theta_{0}, \theta_{1}},
    & \Rightarrow &
        \phi_{0}(x) = 1
    \nonumber
    \\
    p_{\theta_{1}}(x)
    <
    kp_{\theta_{0}}(x),
    \
    x \in \mathcal{X}_{\theta_{0}, \theta_{1}},
    & \Rightarrow &
        \phi_{0}(x) = 0
        \label{chap03_03_24}
    .
\end{eqnarray}
$$

<div class="end-of-statement" style="text-align: right">■</div>
